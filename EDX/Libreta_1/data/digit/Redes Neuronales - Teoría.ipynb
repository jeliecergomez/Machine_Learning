{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es una Red Neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Una red neuronal es un modelo computacional vagamente inspirado en el comportamiento biológico encontrado en las neuronas de nuestro cerebro. En la siguiente imagén se observa gráficamente un ejemplo de una red neuronal artificial</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/NN_Example.png\" width = \"100%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>En nuestra imagen podemos observar que tenemos tres entradas que se conectaran con las diferentes neuronas que conforman la primera capa de neuronas, las cuales posteriormente se conectarán con las neuronas de la siguiente capa. Lo cual se repetirá hasta llegar a la capa de salida. En la siguiente imagen se observa la \"anatomía\" de cada una de las neuronas:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Neurona.png\" width = \"80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Dejando un poco de lado la analogia biologica, los componentes matemáticos que describiremos primeramente son el vector a, la matriz W y el vector b.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Var_entrada_neurona.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>El vector \"<b>a</b>\" conocido como vector de activación, corresponde a la salida de las neuronas anteriores las cuales representan la información almacenada por cada una de las neuronas de la capa anterior, el vector tiene un tamaño igual a la cantidad de neuronas que conformaban la capa anterior.</p>\n",
    "<p style='text-align: justify;'>La matriz de pesos \"<b>W</b>\"  donde se almacenan cada uno de los pesos de las aristas que unen a cada una de las neuronas de la capa anterior con las neuronas de la capa siguiente. Las dimensiones de esta matriz son un número de renglones iguales a la cantidad de neuronas de la próxima capa, mientras que un numero de filas igual a las neuronas de esta capa.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/DescripcionW0.png\" width = \"85%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/EjemploW0.png\" width = \"55%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>El vector \"<b>b</b>\" representa el efecto que tiene la variable \"<b>bías</b>\" al ser multiplicada por el peso de cada una de las aristas que une al bias con cada una de las neuronas de la siguiente capa. Esta variable nos permite regular el umbral de comportamiento de la neurona. </p>\n",
    "<p style='text-align: justify;'>Cómo se observó en la imagen de la neurona, esta recibe cada una de las variables de activación de la capa anterior después de ser multiplicada por los pesos de las aristas correspondientes y las suma con el peso asociado al bias que recibe. Lo anterior es posible generalizarlo para todas las neuronas de la siguiente capa aplicando un poco de operaciones de matrices como se observa a continuación: </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/CalculoZ_1.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>El vector \"<b>Z</b>\" representará el contenido de cada una de las neuronas de la siguiente capa.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/CalculoZ_2.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Es posible compactar un poco la escritura, de tal forma que el vector \"<b>Z</b>\" se puede escribir en terminos de las siguientes sumatorias:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/CalculoZ_3.png\" width = \"100%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>El contenido de la capa cero de neuronas está en función de las entradas de la red neuronal, el resto de las capas está en función de la activación de la capa anterior. Antes de continuar con el proceso, el contenido de la neurona debe pasar por una función de activación.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/EjemploNeurona.png\" width = \"80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>La función de activación más utilizada es la función sigmoide, en la siguiente imagen describe esta función de activación:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/FuncionActivacion.png\" width = \"80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ¿Cómo funciona una Red Neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>En la siguiente imagen se ve cómo se propaga la información dentro de la red.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Neural Network.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation (Feed Forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>El proceso que modifica la información de entrada hasta convertirlo en la información de salida se conoce como Forward Propagation y es un procedimiento iterativo donde la activación de una capa al interactuar con los pesos de las aristas de la próxima capa y el conjunto de pesos ponderados de los bias producirán la información de cada una de las neuronas de la próxima capa, información que posteriormente se introducirá en una función de activación. La información resultante de esta serie de operaciones matemáticas será la entrada de la siguiente capa.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/ForwardPropagation.png\" width = \"100%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>¿Pero cómo es posible saber que la respuesta de la red neuronal es la correcta?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Output_doubt.png\" width = \"80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo del error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Debido a que la red neuronal se utiliza para predecir el comportamiento que tendrá una entrada, es posible saber que tan bien se desempeña la red si comparamos el valor de salida previamente conocido para un entrada con el valor que devuelve la red cuando se introduce la misma entrada. Lo anterior puede generalizarse para cada una de las sesiones de entrenamiento donde el error acumulado se calcula utilizando la siguiente ecuación (<b>MSE Median Square Error</b>):</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/CalculoError.png\" width = \"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Es evidente que siempre se busca que el error devuelto sea lo minimo, motivo por el cual se pretende minimizar la función de error. Los componentes qué pudieron generar ese error son los siguientes:</p>\n",
    "\n",
    "- Las entradas.\n",
    "- Los pesos de las aristas.\n",
    "- Los bias y sus pesos asociados.\n",
    "\n",
    "<p style='text-align: justify;'>Debido a que las entradas de la red no pueden \"corregirse\", solamente podemos modificar los valores de los pesos y las bias. Matemáticamente podemos escribir al error en función de lo anterior y utilizando el concepto de la derivada parcial podemos buscar cuanto afecta cada uno de estos elementos al error. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Errores.png\" width = \"80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Para fines de simplificar cuánto afectan los elementos al error, nos centraremos en cuánto afectan los elementos ante solo una predicción, de tal forma que trabajaremos con la ecuación siguiente: </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/errorIndividual.png\" width = \"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Imaginemos brevemente una red neuronal con un solo peso, si graficáramos 3 configuraciones diferentes de ese peso con respecto al error producido se vería algo similar a la siguiente figura: </p>\n",
    "<center><img src=\"img/localopt.png\" width = \"50%\"></center>\n",
    "<p style='text-align: justify;'>Como nuestra tarea es encontrar el error que minimice el error total, debemos siempre estar cambiando los pesos de acuerdo con la pendiente pues esta nos llevara al optimo local. Para calcular la pendiente en este ejemplo sencillo basta calcular el error con valores ligeramente mayor y menor del peso analizado. Esto nos dará una idea de la pendiente. </p>\n",
    "<p style='text-align: justify;'>Cuando lo escalamos a una red completa este proceso se complica pues podemos manejar miles incluso millones de números simultáneamente. Existe una alternativa que es el <b>cálculo de la gradiente</b>. Esta nos permitirá obtener en un espacio multidimensional un vector que nos indica la dirección del mínimo local. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error respecto a los pesos W2 y los Bias B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Backward_W2.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/DerivadaW2_Parte1.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/DerivadaW2_Parte2.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Sabemos que el procedimiento anterior es tedioso o difícil de realizar, a continuación te presentaremos directamente las ecuaciones del resto de las derivadas parciales, pero se invita a los interesados a darse una oportunidad e intentar resolver por su cuenta las derivadas restantes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/DerivadaB2.png\" width = \"40%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error respecto a los pesos W1 y los Bias B1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Backward_W1.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/DerivadaW1B1.png\" width = \"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error respecto a los pesos W0 y los Bias B0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/Backward_W0.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/DerivadaW0B0.png\" width = \"70%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo se actualiza la red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/ActualizaciónElementos.png\" width = \"70%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema de detección de números manuscritos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Ahora que ya definimos los elementos que conforman una red neuronal artificial abordaremos como ejemplo el problema del reconocimiento de números manuscritos. En este problema tenemos números escaneados en imágenes de 28*28 píxeles donde cada pixel puede tener un valor de 0 si se encuentra vacío y 1 si tiene tinta del número escrito.</p> \n",
    "\n",
    "<p style='text-align: justify;'>Nuestro objetivo será el diseñar un programa que sea capaz de determinar de forma automática cada uno de los números que esté recibiendo como entrada. Si lo intentamos resolver con programación típica es un problema muy difícil pero utilizando una red neuronal podremos realizar esta tarea de forma sencilla.</p>\n",
    "<center><img src=\"img/numero.png\" width = \"60%\"></center>\n",
    "<p style='text-align: justify;'>En el siguiente vídeo veremos cómo se diseña una red neuronal para resolver este problema.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción X-OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Antes de definir con lujo de detalle cada uno de los componentes de la red neuronal y la matemática relacionada, te presentaremos una red pequeña con la finalidad de que te familiarices con el tema.  El objetivo de esta red será predecir si un número binario tiene una cantidad par o impar de bits con el valor de uno.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| A \t| B \t| C \t| Y \t|\n",
    "|:--:\t|:--:\t|:--:\t|:-:\t|\n",
    "|  0 \t|  0 \t|  0 \t| 0 \t|\n",
    "|  0 \t|  0 \t|  1 \t| 1 \t|\n",
    "| 0  \t| 1  \t| 0  \t| 1 \t|\n",
    "| 0  \t| 1  \t| 1  \t| 0 \t|\n",
    "| 1  \t| 0  \t| 0  \t| 1 \t|\n",
    "| 1  \t| 0  \t| 1  \t| 0 \t|\n",
    "|  1 \t|  1 \t|  0 \t| 0 \t|\n",
    "| 1  \t| 1  \t| 1  \t| 1 \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>En la tabla anterior se muestra que en la primera entrada donde todos los bits son cero, la salida es cero pero en la última entrada donde todos los bits son uno, la salida es uno. Cuando tenemos una cantidad par de unos se asignará una salida de cero y en caso contrario se asigna una salida de uno. La red neuronal que verás a continuación funcionará de manera similar.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arreglos de entrenamiento.\n",
    "X = np.array(([0,0,0],\n",
    "              [0,0,1],\n",
    "              [0,1,0],\n",
    "              [0,1,1],\n",
    "              [1,0,0],\n",
    "              [1,0,1],\n",
    "              [1,1,0],\n",
    "              [1,1,1]), dtype = float)\n",
    "\n",
    "y = np.array(([0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0],\n",
    "              [1],\n",
    "              [0],\n",
    "              [0],\n",
    "              [1]), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/NN_XOR.png\" width = \"90%\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "w0 = np.random.randn(X.shape[1],4)\n",
    "w1 = np.random.randn(4, 1)\n",
    "output = np.zeros(y.shape)\n",
    "Z0,z1,a0,a1,a2,errors = [],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pesos de la capa cero.\n",
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesos de la capa uno.\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conozcamos la salida.\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1/(1+np.exp(-t))\n",
    "\n",
    "def sigmoid_derivative(p):\n",
    "    return sigmoid(p) * sigmoid(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(X_input):\n",
    "    \n",
    "    #np.dot regresa el producto punto de dos arreglos.\n",
    "    global a0,z0,a1,z1,a2\n",
    "    \n",
    "    # La activación de la capa cero, es la entrada.\n",
    "    a0 = X_input\n",
    "    z0 = np.dot(a0,w0) # NOTA: En esta sección se sumarían los baias si existieran.\n",
    "    \n",
    "    # La activación de la capa uno, es la información de las neuronas anteriores (Entradas)  \n",
    "    # a través de la función de activación \"sigmoide\".\n",
    "    a1 = sigmoid(z0)\n",
    "    z1 = np.dot(a1,w1)\n",
    "    \n",
    "    # La activación de la capa dos, es la información de las neuronas anteriores (Capa 1)  \n",
    "    # a través de la función de activación \"sigmoide\".\n",
    "    a2 = sigmoid(z1)\n",
    "    \n",
    "    # En esta red, aquí terminamos, porque no hay más capas.\n",
    "    output = a2\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop():\n",
    "    # Aplicando la regla de la cadena para la función de perdida respecto a los pesos 2 y 1.\n",
    "    # .T devuelve la matriz traspuesta\n",
    "    global w0,w1,w2,b0,b1,b2\n",
    "    \n",
    "    # Calcular el error MSE --> Mean Square Error.\n",
    "    mse = np.sum( (1 / 2) * (y - output) * (y - output))\n",
    "    errors.append(mse)\n",
    "\n",
    "    delta1 = -(y - output) * sigmoid_derivative(z1)\n",
    "    d_w1 = np.dot(a1.T,delta1)\n",
    "    d_b1 = delta1\n",
    "    \n",
    "    delta0 = np.dot(delta1,w1.T) * sigmoid_derivative(z0)\n",
    "    d_w0 = np.dot(a0.T,delta0)\n",
    "    d_b0 = delta0\n",
    "\n",
    "    # lr --> Learning Rate, es un parametro propuesto por el investigador\n",
    "    # que indica que tanta importancia le asignamos a los errores del pasado.\n",
    "    w1 = w1 - lr * d_w1\n",
    "    w0 = w0 - lr * d_w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sesión de entrenamiento\n",
    "repeticiones = 1000\n",
    "\n",
    "for i in range(repeticiones):\n",
    "    # Primero se realiza el feedforward y despues el back propagation\n",
    "    output = feedforward(X)\n",
    "    backprop()\n",
    "    # Las siguientes líneas muestran el error cada 10 sesiones.\n",
    "    if i % 10 == 0:\n",
    "        print(\"Epoch: {}, mse: {}\".format(i,errors[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usemos la red para predecir una entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrada propuesta $x = [1,0,1]$\n",
    "<br>Salida esperada $y=0$ (Debido a que tiene un número Par de unos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La salida es igual a la predicción de la red ante una entrada.\n",
    "output = feedforward([1,0,1])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafiquemos los errores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo podemos mejorar el desempeño?\n",
    "No existe una alternativa única pero se pueden intentar las siguientes alternativas:\n",
    "<br>1) Incrementar la sesiones de entrenamiento.\n",
    "<br>2) Experimentar modificando el valor de la taza de aprendizaje ($lr$).\n",
    "<br>3) Proponer otra configuración de red neuronal.\n",
    "<br>4) Incluir Baias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelve a reiniciar la libreta pero antes de ejecutar las celdas donde se define el número de sesiones de entrenamiento, aumenta la variable de $200$ a $500$. Compara con el valor obtenido anterior de la predicción y del último error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

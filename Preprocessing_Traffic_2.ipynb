{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac91067-e43b-4233-85ad-9ae43c0ca8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 1 --Hasta ahora es el mejor código para preprocesar los datos\n",
    "import csv\n",
    "total_datos = 0\n",
    "elephant=0\n",
    "my_flow=''\n",
    "\n",
    "def write_file(src_ip, dst_ip, src_port,dst_port,bidirectional_first_seen_ms,bidirectional_last_seen_ms,bidirectional_bytes,target_traffic):\n",
    "\n",
    "  \n",
    "     with open('/Machine Learning/Data/trafficunicor_ml.csv', mode='a') as csv_file:\n",
    "            fieldnames = ['src_ip', 'dst_ip', 'src_port','dst_port','bidirectional_first_seen_ms','bidirectional_last_seen_ms','bidirectional_bytes','target_traffic']\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            #writer.writeheader()\n",
    "            writer.writerow({'src_ip': src_ip,'dst_ip':dst_ip, 'src_port':src_port,'dst_port': dst_port,'bidirectional_first_seen_ms':bidirectional_first_seen_ms,'bidirectional_last_seen_ms':bidirectional_last_seen_ms,'bidirectional_bytes':bidirectional_bytes,'target_traffic':target_traffic})\n",
    "\n",
    "      \n",
    "def comparar(ip_scr,ip_des,pt_scr,pt_dest):\n",
    "        type_trafic=0\n",
    "        bidirectional_bytes=0\n",
    "        umbral=67000\n",
    "        ln_count = 0\n",
    "        global elephant\n",
    "        global total_datos\n",
    "        global my_flow\n",
    "        with open('/Machine Learning/Data/traficunicor.csv') as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                for row in csv_reader:\n",
    "                    if  ln_count== 0:\n",
    "                        #print(f'Column names are {\", \".join(row)}')\n",
    "                        ln_count += 1\n",
    "                        #write_file(my_flow)\n",
    "                    else:\n",
    "                        my_flow=[row[2],row[6],row[5],row[9],row[14],row[15],row[18]]\n",
    "                        if (ip_scr=={row[2]} and ip_des=={row[6]} and pt_scr=={row[5]} and pt_dest=={row[9]}  ):\n",
    "                            bidirectional_bytes+=int(row[18])\n",
    "                            \n",
    "                            ln_count += 1\n",
    "                        else:\n",
    "                            ln_count += 1\n",
    "                    \n",
    "        if (bidirectional_bytes>umbral):\n",
    "            elephant+=1\n",
    "            type_trafic=1\n",
    "     \n",
    "        return type_trafic\n",
    "\n",
    "with open('/Machine Learning/Data/traficunicor.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        ip_count=0\n",
    "        ip_origen=''\n",
    "        ip_destino=''\n",
    "        pto_origen=''\n",
    "        pto_destino=''\n",
    "        bidirectional_bytes=0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                ip_origen={row[2]}\n",
    "                ip_destino={row[6]}\n",
    "                pto_origen={row[5]}\n",
    "                pto_destino={row[9]}\n",
    "                if (comparar(ip_origen,ip_destino,pto_origen, pto_destino)==0):\n",
    "                 write_file(row[2],row[6],row[5],row[9],row[14],row[15],row[18],'0' )\n",
    "                else :\n",
    "                    write_file(row[2],row[6],row[5],row[9],row[14],row[15],row[18],'1' )\n",
    "                line_count += 1\n",
    "                total_datos += 1\n",
    "print('Total Datos', total_datos)\n",
    "print('Total trafico elefante', elephant)\n",
    "print ('ultima ip', my_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7690ae7d-98cf-4d84-ad5a-d5a49ed7d90f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23620/4227167972.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0mpto_origen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mpto_destino\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomparar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mip_origen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mip_destino\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpto_origen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpto_destino\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m                  \u001b[0mwrite_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbidirectional_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23620/4227167972.py\u001b[0m in \u001b[0;36mcomparar\u001b[1;34m(ip_scr, ip_des, pt_scr, pt_dest)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Machine Learning/Data/traficunicor.csv'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mcsv_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsv_reader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                     \u001b[1;32mif\u001b[0m  \u001b[0mln_count\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                         \u001b[1;31m#print(f'Column names are {\", \".join(row)}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jegjo\\appdata\\local\\programs\\python\\python38\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Version 1.1 --Hasta ahora es el mejor código para preprocesar los datos\n",
    "import csv\n",
    "total_datos = 0\n",
    "elephant=0\n",
    "my_flow=''\n",
    "bidirectional_bytes=0\n",
    "def write_file(src_ip, dst_ip, src_port,dst_port,bidirectional_first_seen_ms,bidirectional_last_seen_ms,bidirectional_bytes,target_traffic,size_traffic):\n",
    "\n",
    "  \n",
    "     with open('/Machine Learning/Data/trafficunicor_ml_2.csv', mode='a') as csv_file:\n",
    "            fieldnames = ['src_ip', 'dst_ip', 'src_port','dst_port','bidirectional_first_seen_ms','bidirectional_last_seen_ms','bidirectional_bytes','target_traffic','size_traffic']\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            #writer.writeheader()\n",
    "            writer.writerow({'src_ip': src_ip,'dst_ip':dst_ip, 'src_port':src_port,'dst_port': dst_port,'bidirectional_first_seen_ms':bidirectional_first_seen_ms,'bidirectional_last_seen_ms':bidirectional_last_seen_ms,'bidirectional_bytes':bidirectional_bytes,'target_traffic':target_traffic,'size_traffic':size_traffic})\n",
    "\n",
    "      \n",
    "def comparar(ip_scr,ip_des,pt_scr,pt_dest):\n",
    "        type_trafic=0\n",
    "        global bidirectional_bytes \n",
    "        umbral=44873554\n",
    "        ln_count = 0\n",
    "        global elephant\n",
    "        global total_datos\n",
    "        global my_flow\n",
    "        with open('/Machine Learning/Data/traficunicor.csv') as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                for row in csv_reader:\n",
    "                    if  ln_count== 0:\n",
    "                        #print(f'Column names are {\", \".join(row)}')\n",
    "                        ln_count += 1\n",
    "                        #write_file(my_flow)\n",
    "                    else:\n",
    "                        my_flow=[row[2],row[6],row[5],row[9],row[14],row[15],row[18]]\n",
    "                        if (ip_scr=={row[2]} and ip_des=={row[6]} and pt_scr=={row[5]} and pt_dest=={row[9]}  ):\n",
    "                            bidirectional_bytes+=int(row[18])\n",
    "                            \n",
    "                            ln_count += 1\n",
    "                        else:\n",
    "                            ln_count += 1\n",
    "                    \n",
    "        if (bidirectional_bytes>umbral):\n",
    "            elephant+=1\n",
    "            type_trafic=1\n",
    "     \n",
    "        return type_trafic\n",
    "\n",
    "with open('/Machine Learning/Data/traficunicor.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        ip_count=0\n",
    "        ip_origen=''\n",
    "        ip_destino=''\n",
    "        pto_origen=''\n",
    "        pto_destino=''\n",
    "        bidirectional_bytes=0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                bidirectional_bytes=0\n",
    "                ip_origen={row[2]}\n",
    "                ip_destino={row[6]}\n",
    "                pto_origen={row[5]}\n",
    "                pto_destino={row[9]}\n",
    "                if (comparar(ip_origen,ip_destino,pto_origen, pto_destino)==0):\n",
    "                 write_file(row[2],row[6],row[5],row[9],row[14],row[15],row[18],'0',bidirectional_bytes)\n",
    "                else :\n",
    "                    write_file(row[2],row[6],row[5],row[9],row[14],row[15],row[18],'1',bidirectional_bytes )\n",
    "                line_count += 1\n",
    "                total_datos += 1\n",
    "print('Total Datos', total_datos)\n",
    "print('Total trafico elefante', elephant)\n",
    "print ('ultima ip', my_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5afea8b-ad8e-4b78-9a80-746d63115b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 1.2 --Hasta ahora es el mejor código para preprocesar los datos\n",
    "import csv\n",
    "total_datos = 0\n",
    "elephant=0\n",
    "my_flow=''\n",
    "last_ip=''\n",
    "bidirectional_bytes=0\n",
    "def write_file(src_ip, dst_ip, src_port,dst_port,bidirectional_first_seen_ms,bidirectional_last_seen_ms,bidirectional_bytes,target_traffic,size_traffic):\n",
    "\n",
    "  \n",
    "     with open('/Machine Learning/Data/trafficunicor_ml_2.csv', mode='a') as csv_file:\n",
    "            fieldnames = ['src_ip', 'dst_ip', 'src_port','dst_port','bidirectional_first_seen_ms','bidirectional_last_seen_ms','bidirectional_bytes','target_traffic','size_traffic']\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            #writer.writeheader()\n",
    "            writer.writerow({'src_ip': src_ip,'dst_ip':dst_ip, 'src_port':src_port,'dst_port': dst_port,'bidirectional_first_seen_ms':bidirectional_first_seen_ms,'bidirectional_last_seen_ms':bidirectional_last_seen_ms,'bidirectional_bytes':bidirectional_bytes,'target_traffic':target_traffic,'size_traffic':size_traffic})\n",
    "\n",
    "      \n",
    "def comparar(ip_scr,ip_des,pt_scr,pt_dest):\n",
    "        type_trafic=0\n",
    "        global bidirectional_bytes \n",
    "        umbral=44873554\n",
    "        ln_count = 0\n",
    "        global elephant\n",
    "        global total_datos\n",
    "        global my_flow\n",
    "        with open('/Machine Learning/Data/traficunicor.csv') as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                for row in csv_reader:\n",
    "                    if  ln_count== 0:\n",
    "                        #print(f'Column names are {\", \".join(row)}')\n",
    "                        ln_count += 1\n",
    "                        #write_file(my_flow)\n",
    "                    else:\n",
    "                        \n",
    "                        my_flow=[row[2],row[6],row[5],row[9],row[14],row[15],row[18]]\n",
    "                        if (ip_scr=={row[2]} and ip_des=={row[6]} and pt_scr=={row[5]} and pt_dest=={row[9]}  ):\n",
    "                            bidirectional_bytes+=int(row[18])\n",
    "                            \n",
    "                            ln_count += 1\n",
    "                            if (bidirectional_bytes>umbral):\n",
    "                                    break\n",
    "                        else:\n",
    "                            ln_count += 1\n",
    "                    \n",
    "        if (bidirectional_bytes>umbral):\n",
    "            elephant+=1\n",
    "            type_trafic=1\n",
    "     \n",
    "        return type_trafic\n",
    "\n",
    "with open('/Machine Learning/Data/traficunicor.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        ip_count=0\n",
    "        ip_origen=''\n",
    "        ip_destino=''\n",
    "        pto_origen=''\n",
    "        pto_destino=''\n",
    "        bidirectional_bytes=0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                bidirectional_bytes=0\n",
    "                ip_origen={row[2]}\n",
    "                ip_destino={row[6]}\n",
    "                pto_origen={row[5]}\n",
    "                pto_destino={row[9]}\n",
    "                if (comparar(ip_origen,ip_destino,pto_origen, pto_destino)==0):\n",
    "                 write_file(row[2],row[6],row[5],row[9],row[14],row[15],row[18],'0',bidirectional_bytes)\n",
    "                else :\n",
    "                    write_file(row[2],row[6],row[5],row[9],row[14],row[15],row[18],'1',bidirectional_bytes )\n",
    "                line_count += 1\n",
    "                total_datos += 1\n",
    "print('Total Datos', total_datos)\n",
    "print('Total trafico elefante', elephant)\n",
    "print ('ultima ip', my_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d558e-b1ae-4360-a475-85d6c110e760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
